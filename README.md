# Papers for Reference

## VLM

### Transfering

* CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction | Size Wu, Wenwei Zhang, Lumin Xu, Sheng Jin, Xiangtai Li, Wentao Liu, Chen Change Loy
    * Links: [arXiv:2310.01403](https://arxiv.org/abs/2310.01403) | [GitHub](https://github.com/wusize/CLIPSelf)
    * Keypoints: Enhance the local region representation of CLIP for downstream open-vocabulary dense prediction tasks.

## Unified Architecture

### Multi-Modal

* TCSVT 2021 | SwinNet: Swin Transformer drives edge-aware RGB-D and RGB-T salient object detection | Zhengyi Liu, Yacheng Tan, Qian He, Yun Xiao
    * Links: [arXiv:2204.05585](https://arxiv.org/abs/2204.05585) | [GitHub](https://github.com/liuzywen/SwinNet)
    * Keypoints: Unified architecture and separate parameter for RGB-Depth/Thermal SOD.
* TIP 2023 | CAVER: Cross-Modal View-Mixed Transformer for Bi-Modal Salient Object Detection | Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu
    * Links: [arXiv:2112.02363](https://arxiv.org/abs/2112.02363) | [GitHub](https://github.com/lartpang/CAVER)
    * Keypoints: Unified architecture and separate parameter for RGB-Depth/Thermal SOD.
* All in One: RGB, RGB-D, and RGB-T Salient Object Detection | Xingzhao Jia, Zhongqiu Zhao, Changlei Dongye, Zhao Zhang
    * Links: [arXiv:2311.14746](https://arxiv.org/abs/2311.14746)
    * Keypoints: Unified architecture and separate parameter for RGB-RGB/Depth/Thermal SOD.
* VSCode: General Visual Salient and Camouflaged Object Detection with 2D Prompt Learning | Ziyang Luo, Nian Liu, Wangbo Zhao, Xuguang Yang, Dingwen Zhang, Deng-Ping Fan, Fahad Khan, Junwei Han
    * Links: [arXiv:2311.15011](https://arxiv.org/abs/2311.15011)
    * Keypoints: Unified architecture and separate prompts for joint learning from RGB-RGB/Depth/Thermal/Flow SOD and RGB-RGB/Depth/Flow COD based on domain-specific and task-specific parameters (prompts).
